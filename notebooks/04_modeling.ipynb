{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b91c31",
   "metadata": {},
   "source": [
    "# 04 modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b0cef-788a-4c4e-8742-70ba325da36f",
   "metadata": {},
   "source": [
    "## a. Key Considerations from Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f7e79-a14e-4508-8f09-c10fc56b3cc3",
   "metadata": {},
   "source": [
    "1. Small sample size -  We will need models that are robust to overfitting and don’t require massive data.\n",
    "\n",
    "2. Mostly categorical features - Well need algorithms that naturally handle categorical variables or can work well after encoding are suitable.\n",
    "\n",
    "3. Binary outcome - almost any classifier works, but stability matters more than raw complexity here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063d281-607d-4791-9c9d-ab45a6e8db24",
   "metadata": {},
   "source": [
    "## b. Best algorithm choice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dffcd0-1bea-4894-95ee-19612d7a76a1",
   "metadata": {},
   "source": [
    "1. Logistic Regression \n",
    "\n",
    "    Will be our baseline as it is simple, interpretable, and works well with small datasets.\n",
    "    \n",
    "    Needs one-hot encoding or similar for categorical variables.\n",
    "    \n",
    "    Needs regularization (L1/L2) helps prevent overfitting.\n",
    "\n",
    "2. Decision Tree–based models - CatBoost\n",
    "    \n",
    "    CatBoost natively handles categorical features.\n",
    "    \n",
    "    Good at capturing nonlinear relationships.\n",
    "    \n",
    "    CatBoost might squeeze out more accuracy but risks overfitting.\n",
    "\n",
    "3. Naïve Bayes - CategoricalNB\n",
    "\n",
    "    Works well on small categorical-heavy datasets.\n",
    "    \n",
    "    Fast to train, interpretable.\n",
    "    \n",
    "    Assumes feature independence, which is often not true, but it’s robust enough for small data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae511a-1a6a-4914-a4b4-7c7eb9daccfb",
   "metadata": {},
   "source": [
    "## c. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02bf1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6880f-ba59-4d2a-a28b-209af52b2fcb",
   "metadata": {},
   "source": [
    "## d. Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "613585c1-4ead-4544-9c06-a8d3d6e40aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# ===== Defining the data directories ==== #\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\Window\\Desktop\\Everything_Data_Mentorship\\mentorship_ds_project\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "COMMON_DATA_DIR = DATA_DIR / \"raw\"\n",
    "INGESTED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# ===== Define artifact and data file paths ==== #\n",
    "preprocessor_file = PROJECT_ROOT / \"artifacts\" / \"preprocessor.joblib\"\n",
    "X_train_file = INGESTED_DIR / \"X_train.csv\"\n",
    "X_test_file = INGESTED_DIR / \"X_test.csv\"\n",
    "y_train_file = INGESTED_DIR / \"y_train.csv\"\n",
    "y_test_file = INGESTED_DIR / \"y_test.csv\"\n",
    "\n",
    "# ===== Load the preprocessor and data ==== #\n",
    "preprocessor = joblib.load(preprocessor_file)\n",
    "\n",
    "X_train = pd.read_csv(X_train_file)\n",
    "X_test = pd.read_csv(X_test_file)\n",
    "y_train = pd.read_csv(y_train_file).squeeze()  # convert DataFrame to Series\n",
    "y_test = pd.read_csv(y_test_file).squeeze()\n",
    "\n",
    "# ===== Transform ==== #\n",
    "X_train_final = preprocessor.transform(X_train)\n",
    "X_test_final = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dce64-0992-4504-bb27-b436c485c9dd",
   "metadata": {},
   "source": [
    "## e. Baseline Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddce82f4-205d-444c-8b9a-14036901b611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7391304347826086\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        17\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.37      0.50      0.42        23\n",
      "weighted avg       0.55      0.74      0.63        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_final[:, -1:] = scaler.fit_transform(X_train_final[:, -1:])\n",
    "X_test_final[:, -1:]  = scaler.transform(X_test_final[:, -1:])\n",
    "\n",
    "# Initialize logistic regression (baseline, minimal tuning)\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc3fbe-08f6-44f6-a2cd-b9d0e73479ce",
   "metadata": {},
   "source": [
    "The warning often means the model isn’t predicting one or more labels at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4d31a-ca76-4fdf-8d25-875460e2dc1e",
   "metadata": {},
   "source": [
    "### Baseline model Observations\n",
    "\n",
    "Overall, the model correctly predicts 73.3% of the test set.\n",
    "\n",
    "Class 0 (majority class) has 17 samples, while Class 1 (minority class) has only 6 samples.\n",
    "\n",
    "The model always predicts class 0 (recall for class 1 is 0.00), which artificially inflates accuracy.\n",
    "\n",
    "Precision = 0.74, Recall = 1.00, F1 = 0.85 → The model is excellent at identifying class 0.\n",
    "\n",
    "Precision = 0.00, Recall = 0.00, F1 = 0.00 → The model completely fails to detect class 1.\n",
    "\n",
    "The weighted average is dominated by class 0, again hiding the model’s inability to recognize class 1.\n",
    "\n",
    "### Baseline model conclusion\n",
    "The program is over-predicting dropouts - class 0.\n",
    "\n",
    "The model defaults to predicting \"did not graduate\" for everyone.\n",
    "\n",
    "This suggests our features are not separating graduates from non-graduates well.\n",
    "\n",
    "### Why this is problematic\n",
    "\n",
    "Our goal is to identify students who are likely to graduate therefore this model is useless as it provides no signal for class 1 - graduates.\n",
    "\n",
    "The accuracy score is misleading because our dataset is imbalanced - 74% of the samples are non-graduates.\n",
    "\n",
    "### Impact\n",
    "\n",
    "Stakeholders would miss out on identifying potential graduates or at-risk students.\n",
    "\n",
    "Any interventions based on this model would only ever target the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebe9975-5ae3-496f-bc1f-c1c172afd271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts/log_reg_baseline.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the trained model\n",
    "joblib.dump(log_reg, 'artifacts/log_reg_baseline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e093ec-ec06-4d56-9538-8cdbccdd1eef",
   "metadata": {},
   "source": [
    "### Improving peformance of the baseline model\n",
    "\n",
    "#### 1. Adjust Class Weights. \n",
    "This penalizes misclassification of graduates more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470694f1-9ed7-483d-912d-bceec384661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58        17\n",
      "           1       0.11      0.17      0.13         6\n",
      "\n",
      "    accuracy                           0.43        23\n",
      "   macro avg       0.38      0.35      0.36        23\n",
      "weighted avg       0.50      0.43      0.46        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_final[:, -1:] = scaler.fit_transform(X_train_final[:, -1:])\n",
    "X_test_final[:, -1:]  = scaler.transform(X_test_final[:, -1:])\n",
    "\n",
    "# Initialize logistic regression with class_weight as balanced\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7101b-e657-4188-b74c-64b559395d4a",
   "metadata": {},
   "source": [
    "### Adjusted class_weight = \"balanced\" model observations\n",
    "Our results after setting class_weight='balanced' show a clear shift in how the model treats the minority class (graduates).\n",
    "\n",
    "The model now predicts some graduates (class 1) as th recall improved from 0.00 → 0.17, which is progress for the minority class.\n",
    "\n",
    "Accuracy dropped, this is expected as the model is no longer “playing it safe” by always predicting the majority class - class 0.\n",
    "\n",
    "Precision for class 1(graduates) remains low therefore most graduate predictions are still incorrect, indicating the features don’t yet strongly distinguish graduates.\n",
    "\n",
    "Macro averages decreased slightly because accuracy is no longer inflated by ignoring class 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf64aeb-c485-4515-8a89-16a8d1843a31",
   "metadata": {},
   "source": [
    "#### 2. Hyperparameter tuning using GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8723deac-1095-4139-a401-ab8edbb20cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the base model\n",
    "log_reg = LogisticRegression(class_weight='balanced', max_iter=500, solver='liblinear')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 2.0, 5.0, 10.0],   # Regularization strength (higher C = less regularization)\n",
    "    'penalty': ['l1', 'l2']                  # Try both L1 and L2 penalties\n",
    "}\n",
    "\n",
    "# Grid search with stratified 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                 # Stratified 5-fold CV\n",
    "    scoring='f1_macro',   # Macro F1 balances both classes\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9760c784-a624-40b1-9e0f-4cd487e25bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'penalty': 'l1'}\n",
      "Best Macro F1 Score: 0.5227731092436975\n"
     ]
    }
   ],
   "source": [
    "#Fit on the data\n",
    "grid_search.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Macro F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a83c74-10ef-4ea4-af7e-75679668a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5217391304347826\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.47      0.59        17\n",
      "           1       0.31      0.67      0.42         6\n",
      "\n",
      "    accuracy                           0.52        23\n",
      "   macro avg       0.55      0.57      0.51        23\n",
      "weighted avg       0.67      0.52      0.55        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best model to predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa64c31-7a33-4e30-8d2b-710e0b1ea2e4",
   "metadata": {},
   "source": [
    "The model is very confident when predicting non-graduates, but when it predicts graduates, it’s often wrong.\n",
    "\n",
    "The model now identifies 67% of actual graduates (recall_score of 0.67), which is a big improvement from 0% recall earlier. However, it now misses many non-graduates (recall dropped from 1.00 to 0.47).\n",
    "\n",
    "Graduates (class 1) have a usable but modest F1-score compared to before (previously 0.00).\n",
    "\n",
    "Accuracy dropped because the model now misclassifies more non-graduates in favor of catching graduates, this is normal when handling class imbalance.\n",
    "\n",
    "Macro and weighted averages are closer, suggesting less bias toward class 0.\n",
    "\n",
    "Our F1-scores are moderate, indicating features or model complexity could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7611708-b771-46a7-ac9c-4208bd24f372",
   "metadata": {},
   "source": [
    " ## f. Stratified k-fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e168a8-80aa-4af6-8d77-258d3e767c08",
   "metadata": {},
   "source": [
    "With only 115 rows, a single 80/20 split means your test set has ~23 rows. Too small to trust. \n",
    "\n",
    "We use StratifiedKFold to preserves class balance instead of one fixed split.\n",
    "\n",
    "    Stratified 5-Fold CV - every observation gets a chance to be in test set, while keeping class balance.\n",
    "    \n",
    "    Produces aggregate predictions across folds - more reliable classification reports and confusion matrices.\n",
    "    \n",
    "    Avoids the “tiny test set” problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6899c3ed-2ff8-43e4-a2c0-90c4d78973ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro scores for each fold: [0.41025641 0.3030303  0.425      0.45591398 0.43047619]\n",
      "Mean F1-macro score: 0.40493537645150546\n",
      "Std deviation: 0.05304092298440999\n",
      "Mean Accuracy: 0.47826086956521746\n"
     ]
    }
   ],
   "source": [
    "# Use all your preprocessed features and labels\n",
    "X_all = preprocessor.transform(pd.concat([X_train, X_test], axis=0).reset_index(drop=True)) # Preprocessed features for the whole dataset\n",
    "y_all = pd.concat([y_train, y_test], axis=0).reset_index(drop=True) # Target labels for the whole dataset\n",
    "\n",
    "#Define Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Define the model with class balancing and best hyperparameters if available\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=500,\n",
    "    solver='liblinear',\n",
    "    C=1.0,  #Best C\n",
    "    penalty=\"l1\" #Best penalty\n",
    ")\n",
    "\n",
    "#Evaluate with F1-macro (better for class imbalance)\n",
    "scores = cross_val_score(log_reg, X_all, y_all, cv=skf, scoring='f1_macro')\n",
    "\n",
    "#Summarize results\n",
    "print(\"F1-macro scores for each fold:\", scores)\n",
    "print(\"Mean F1-macro score:\", np.mean(scores))\n",
    "print(\"Std deviation:\", np.std(scores))\n",
    "\n",
    "#Check accuracy too\n",
    "acc_scores = cross_val_score(log_reg, X_all, y_all, cv=skf, scoring='accuracy')\n",
    "print(\"Mean Accuracy:\", np.mean(acc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905b0a6-b3c6-4565-b13c-9d22c731ce6e",
   "metadata": {},
   "source": [
    "We have moderate variability between folds – the standard deviation of ≈0.053 suggests performance is somewhat stable, but not highly reliable.\n",
    "\n",
    "Low absolute F1-macro and accuracy – the classifier is struggling to separate graduates (class 1) from non-graduates (class 0).\n",
    "\n",
    "Class imbalance likely affects performance – even with class_weight='balanced', the model is biased toward the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58da52cb-cb7c-45c1-bd1c-9d4091808ca1",
   "metadata": {},
   "source": [
    "## g. SMOTE with Logistic Regression and Stratified KFold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e18d1f0-17ad-4a90-949b-62e79cd48f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 Classification Report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Did Not Graduate (0)       0.88      0.41      0.56        17\n",
      "       Graduated (1)       0.33      0.83      0.48         6\n",
      "\n",
      "            accuracy                           0.52        23\n",
      "           macro avg       0.60      0.62      0.52        23\n",
      "        weighted avg       0.73      0.52      0.54        23\n",
      "\n",
      "\n",
      "=== Fold 2 Classification Report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Did Not Graduate (0)       0.79      0.65      0.71        17\n",
      "       Graduated (1)       0.33      0.50      0.40         6\n",
      "\n",
      "            accuracy                           0.61        23\n",
      "           macro avg       0.56      0.57      0.55        23\n",
      "        weighted avg       0.67      0.61      0.63        23\n",
      "\n",
      "\n",
      "=== Fold 3 Classification Report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Did Not Graduate (0)       0.67      0.35      0.46        17\n",
      "       Graduated (1)       0.21      0.50      0.30         6\n",
      "\n",
      "            accuracy                           0.39        23\n",
      "           macro avg       0.44      0.43      0.38        23\n",
      "        weighted avg       0.55      0.39      0.42        23\n",
      "\n",
      "\n",
      "=== Fold 4 Classification Report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Did Not Graduate (0)       0.75      0.71      0.73        17\n",
      "       Graduated (1)       0.29      0.33      0.31         6\n",
      "\n",
      "            accuracy                           0.61        23\n",
      "           macro avg       0.52      0.52      0.52        23\n",
      "        weighted avg       0.63      0.61      0.62        23\n",
      "\n",
      "\n",
      "=== Fold 5 Classification Report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Did Not Graduate (0)       0.69      0.69      0.69        16\n",
      "       Graduated (1)       0.29      0.29      0.29         7\n",
      "\n",
      "            accuracy                           0.57        23\n",
      "           macro avg       0.49      0.49      0.49        23\n",
      "        weighted avg       0.57      0.57      0.57        23\n",
      "\n",
      "F1-macro scores: [0.5180952380952382, 0.5548387096774194, 0.38076923076923075, 0.5174825174825175, 0.48660714285714285]\n",
      "Mean Precision: 0.522 ± 0.057\n",
      "Mean Recall:    0.526 ± 0.068\n",
      "Mean F1-macro: 0.492 ± 0.059\n",
      "Mean Accuracy: 0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [1, 3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_all = pd.concat([X_train, X_test], axis=0).reset_index(drop=True) # Preprocessed features for the whole dataset\n",
    "y_all = pd.concat([y_train, y_test], axis=0).reset_index(drop=True) # Target labels for the whole dataset\n",
    "\n",
    "#Imports \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#Instanciate SMOTE \n",
    "smote = SMOTE(random_state=42, k_neighbors=2)  # k_neighbors can be tuned\n",
    "\n",
    "#Instatiate Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    class_weight=None,\n",
    "    C=1.0, #Best C\n",
    "    random_state=42)\n",
    "\n",
    "#Create a pipeline \n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', smote),\n",
    "    ('log_reg', log_reg)\n",
    "])\n",
    "\n",
    "# Stratified K-Fold setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(X_all, y_all), start=1):\n",
    "    X_train, X_test = X_all.iloc[train_idx], X_all.iloc[test_idx]\n",
    "    y_train, y_test = y_all.iloc[train_idx], y_all.iloc[test_idx]\n",
    "\n",
    "    pipeline.fit(X_train, y_train)      \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Classification report for this fold\n",
    "    print(f\"\\n=== Fold {fold} Classification Report ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Did Not Graduate (0)', 'Graduated (1)']))\n",
    "\n",
    "    # Collect metrics\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "    f1_scores.append(f1)\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "#Results\n",
    "print(f\"F1-macro scores: {f1_scores}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.3f} ± {np.std(precisions):.3f}\")\n",
    "print(f\"Mean Recall:    {np.mean(recalls):.3f} ± {np.std(recalls):.3f}\")\n",
    "print(f\"Mean F1-macro: {np.mean(f1_scores):.3f} ± {np.std(f1_scores):.3f}\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f2255-ddc0-4da9-91c9-c80678d90e62",
   "metadata": {},
   "source": [
    "### SMOTE achieved:\n",
    "\n",
    "Balanced training set per fold, helping the model learn class 1 (“graduated”) patterns better.\n",
    "\n",
    "More stable F1 scores across folds compared to earlier runs.\n",
    "\n",
    "Reduced extreme bias toward class 0, as shown by the improved F1-macro.\n",
    "\n",
    "Better average precision for class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e1673-13b3-4d2b-961e-4557b086523a",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "\n",
    "Accuracy is still moderate (0.557), meaning many predictions remain misclassified.\n",
    "\n",
    "Precision/recall values are close to random guessing (0.5), suggesting the features may not strongly separate the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d208d71-bbd9-4ea2-a7fa-e3bf636d2903",
   "metadata": {},
   "source": [
    "## h. Random Forest; CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d198cd-e1e5-49f8-9e70-1e798fe9b83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'depth': 4, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.2}\n",
      "Best CV Accuracy: 0.5335390025045198\n",
      "Accuracy: 0.6086956521739131\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74        17\n",
      "           1       0.20      0.17      0.18         6\n",
      "\n",
      "    accuracy                           0.61        23\n",
      "   macro avg       0.46      0.47      0.46        23\n",
      "weighted avg       0.59      0.61      0.60        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.features import convert_categorical\n",
    "X_train_cat = convert_categorical(X_train)\n",
    "X_test_cat = convert_categorical(X_test)\n",
    "cat_features = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# Define the base model\n",
    "cat_model = CatBoostClassifier(verbose=0,random_seed=42, cat_features=cat_features)\n",
    "\n",
    "#Define Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Define the param grid\n",
    "param_grid = {\n",
    "    'iterations': [200, 500],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'l2_leaf_reg': [3, 5, 7]\n",
    "}\n",
    "\n",
    "#GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train_final, y_train)\n",
    "\n",
    "#Get the best parameters and score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "#Train a final model using the best parameters on the full training set\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train_final, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60682f11-b0af-4723-9841-cb82a287bfca",
   "metadata": {},
   "source": [
    "Accuracy of 0.61 - Better than Logistic Regression (0.557), but still misses many class 1s.\n",
    "\n",
    "Class 0 F1-score of\t0.74 - The model is very confident predicting non-graduates.\n",
    "\n",
    "Class 1 F1-score of 0.18 - The model struggles to identify graduates (many false negatives).\n",
    "\n",
    "Macro Avg F1-score of 0.46 - Average performance across classes is moderate.\n",
    "\n",
    "Weighted Avg F1-score of 0.60 - Skewed toward class 0 due to class imbalance.\n",
    "\n",
    "Better accuracy and class 0 stability compared to Logistic Regression.\n",
    "\n",
    "CatBoost’s gradient boosting approach can model non-linear relationships better than logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25f8ee-0499-4555-b8a8-f682f463567c",
   "metadata": {},
   "source": [
    "### Challanges\n",
    "Low recall for class 1 (17%) → Most graduates are being misclassified.\n",
    "\n",
    "Small dataset (115 rows) → Limits model’s ability to learn complex patterns.\n",
    "\n",
    "Imbalanced classes → Even with boosting, the model favors the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dadcb-2063-4346-942b-2067b01b0903",
   "metadata": {},
   "source": [
    "## i. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a90f53-b611-44b7-a696-ce58cb8660eb",
   "metadata": {},
   "source": [
    "Baseline Logistic Regression (no scaling, no balancing) - Missed most graduates.\n",
    "\n",
    "Logistic Regression with class_weight='balanced' - Significant improvement in recall for class 1 while keeping a moderate F1.\n",
    "\n",
    "SMOTE + Logistic Regression (Stratified KFold) - Similar to weighted logistic regression. Had good recall for graduates but lower precision. SMOTE helped further balance performance across folds.\n",
    "\n",
    "CatBoost (tuned) - Best overall accuracy, but very poor detection of graduates—it tends to predict class 0.\n",
    "\n",
    "Logistic Regression with SMOTE clearly outperformed the other models for recall and F1 of class 1. \n",
    "\n",
    "Logistic Regression with SMOTE maintained a reasonable trade-off: Mean Accuracy: 0.54 and Mean F1-macro: 0.49 and better recall for class 1, which is our priority.\n",
    "\n",
    "Therefore this model found more actual graduates even if their overall accuracy was slightly lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
