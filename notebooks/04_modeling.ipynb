{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b91c31",
   "metadata": {},
   "source": [
    "# 04 modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b0cef-788a-4c4e-8742-70ba325da36f",
   "metadata": {},
   "source": [
    "## a. Key Considerations from Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f7e79-a14e-4508-8f09-c10fc56b3cc3",
   "metadata": {},
   "source": [
    "1. Small sample size -  We will need models that are robust to overfitting and don’t require massive data.\n",
    "\n",
    "2. Mostly categorical features - Well need algorithms that naturally handle categorical variables or can work well after encoding are suitable.\n",
    "\n",
    "3. Binary outcome - almost any classifier works, but stability matters more than raw complexity here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2063d281-607d-4791-9c9d-ab45a6e8db24",
   "metadata": {},
   "source": [
    "## b. Best algorithm choice "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dffcd0-1bea-4894-95ee-19612d7a76a1",
   "metadata": {},
   "source": [
    "1. Logistic Regression \n",
    "\n",
    "    Will be our baseline as it is simple, interpretable, and works well with small datasets.\n",
    "    \n",
    "    Needs one-hot encoding or similar for categorical variables.\n",
    "    \n",
    "    Needs regularization (L1/L2) helps prevent overfitting.\n",
    "\n",
    "2. Decision Tree–based models - CatBoost\n",
    "    \n",
    "    CatBoost natively handles categorical features.\n",
    "    \n",
    "    Good at capturing nonlinear relationships.\n",
    "    \n",
    "    CatBoost might squeeze out more accuracy but risks overfitting.\n",
    "\n",
    "3. Naïve Bayes - CategoricalNB\n",
    "\n",
    "    Works well on small categorical-heavy datasets.\n",
    "    \n",
    "    Fast to train, interpretable.\n",
    "    \n",
    "    Assumes feature independence, which is often not true, but it’s robust enough for small data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f52e2d-ce39-463d-98de-5047f9b88c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: C:\\Users\\Window\\Desktop\\Everything_Data_Mentorship\\mentorship_ds_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "#print(\"Files in raw folder:\", os.listdir(\"data/raw\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae511a-1a6a-4914-a4b4-7c7eb9daccfb",
   "metadata": {},
   "source": [
    "## c. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bf1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "#import catboost as cb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6880f-ba59-4d2a-a28b-209af52b2fcb",
   "metadata": {},
   "source": [
    "## d. Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613585c1-4ead-4544-9c06-a8d3d6e40aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = joblib.load('artifacts/preprocessor.joblib')\n",
    "\n",
    "# Load original splits\n",
    "X_train = pd.read_csv('data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('data/processed/y_train.csv').squeeze()  # convert DataFrame to Series\n",
    "y_test = pd.read_csv('data/processed/y_test.csv').squeeze()\n",
    "\n",
    "# Transform again if needed\n",
    "X_train_final = preprocessor.transform(X_train)\n",
    "X_test_final = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dce64-0992-4504-bb27-b436c485c9dd",
   "metadata": {},
   "source": [
    "## e. Baseline Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddce82f4-205d-444c-8b9a-14036901b611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7391304347826086\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        17\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.37      0.50      0.42        23\n",
      "weighted avg       0.55      0.74      0.63        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Window\\anaconda3\\envs\\everything_data\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Logistic Regression ---\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_final[:, -1:] = scaler.fit_transform(X_train_final[:, -1:])\n",
    "X_test_final[:, -1:]  = scaler.transform(X_test_final[:, -1:])\n",
    "\n",
    "# Initialize logistic regression (baseline, minimal tuning)\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc3fbe-08f6-44f6-a2cd-b9d0e73479ce",
   "metadata": {},
   "source": [
    "The warning often means the model isn’t predicting one or more labels at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4d31a-ca76-4fdf-8d25-875460e2dc1e",
   "metadata": {},
   "source": [
    "### Baseline model Observations\n",
    "\n",
    "Overall, the model correctly predicts 73.3% of the test set.\n",
    "\n",
    "Class 0 (majority class) has 17 samples, while Class 1 (minority class) has only 6 samples.\n",
    "\n",
    "The model always predicts class 0 (recall for class 1 is 0.00), which artificially inflates accuracy.\n",
    "\n",
    "Precision = 0.74, Recall = 1.00, F1 = 0.85 → The model is excellent at identifying class 0.\n",
    "\n",
    "Precision = 0.00, Recall = 0.00, F1 = 0.00 → The model completely fails to detect class 1.\n",
    "\n",
    "The weighted average is dominated by class 0, again hiding the model’s inability to recognize class 1.\n",
    "\n",
    "### Baseline model conclusion\n",
    "The program is over-predicting dropouts - class 0.\n",
    "\n",
    "The model defaults to predicting \"did not graduate\" for everyone.\n",
    "\n",
    "This suggests our features are not separating graduates from non-graduates well.\n",
    "\n",
    "### Why this is problematic\n",
    "\n",
    "Our goal is to identify students who are likely to graduate therefore this model is useless as it provides no signal for class 1 - graduates.\n",
    "\n",
    "The accuracy score is misleading because our dataset is imbalanced - 74% of the samples are non-graduates.\n",
    "\n",
    "### Impact\n",
    "\n",
    "Stakeholders would miss out on identifying potential graduates or at-risk students.\n",
    "\n",
    "Any interventions based on this model would only ever target the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebe9975-5ae3-496f-bc1f-c1c172afd271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts/log_reg_baseline.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving the trained model\n",
    "joblib.dump(log_reg, 'artifacts/log_reg_baseline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e093ec-ec06-4d56-9538-8cdbccdd1eef",
   "metadata": {},
   "source": [
    "### Improving peformance of the baseline model\n",
    "\n",
    "#### 1. Adjust Class Weights. \n",
    "This penalizes misclassification of graduates more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "470694f1-9ed7-483d-912d-bceec384661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58        17\n",
      "           1       0.11      0.17      0.13         6\n",
      "\n",
      "    accuracy                           0.43        23\n",
      "   macro avg       0.38      0.35      0.36        23\n",
      "weighted avg       0.50      0.43      0.46        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_final[:, -1:] = scaler.fit_transform(X_train_final[:, -1:])\n",
    "X_test_final[:, -1:]  = scaler.transform(X_test_final[:, -1:])\n",
    "\n",
    "# Initialize logistic regression with class_weight as balanced\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = log_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7101b-e657-4188-b74c-64b559395d4a",
   "metadata": {},
   "source": [
    "### Adjusted class_weight = \"balanced\" model observations\n",
    "Our results after setting class_weight='balanced' show a clear shift in how the model treats the minority class (graduates).\n",
    "\n",
    "The model now predicts some graduates (class 1) as th recall improved from 0.00 → 0.17, which is progress for the minority class.\n",
    "\n",
    "Accuracy dropped, this is expected as the model is no longer “playing it safe” by always predicting the majority class - class 0.\n",
    "\n",
    "Precision for class 1(graduates) remains low therefore most graduate predictions are still incorrect, indicating the features don’t yet strongly distinguish graduates.\n",
    "\n",
    "Macro averages decreased slightly because accuracy is no longer inflated by ignoring class 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf64aeb-c485-4515-8a89-16a8d1843a31",
   "metadata": {},
   "source": [
    "#### 2. Hyperparameter tuning using GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8723deac-1095-4139-a401-ab8edbb20cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the base model\n",
    "log_reg = LogisticRegression(class_weight='balanced', max_iter=500, solver='liblinear')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1.0, 2.0, 5.0, 10.0],   # Regularization strength (higher C = less regularization)\n",
    "    'penalty': ['l1', 'l2']                  # Try both L1 and L2 penalties\n",
    "}\n",
    "\n",
    "# Grid search with stratified 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                 # Stratified 5-fold CV\n",
    "    scoring='f1_macro',   # Macro F1 balances both classes\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9760c784-a624-40b1-9e0f-4cd487e25bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'penalty': 'l1'}\n",
      "Best Macro F1 Score: 0.5227731092436975\n"
     ]
    }
   ],
   "source": [
    "#Fit on the data\n",
    "grid_search.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Macro F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53a83c74-10ef-4ea4-af7e-75679668a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5217391304347826\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.47      0.59        17\n",
      "           1       0.31      0.67      0.42         6\n",
      "\n",
      "    accuracy                           0.52        23\n",
      "   macro avg       0.55      0.57      0.51        23\n",
      "weighted avg       0.67      0.52      0.55        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the best model to predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa64c31-7a33-4e30-8d2b-710e0b1ea2e4",
   "metadata": {},
   "source": [
    "The model is very confident when predicting non-graduates, but when it predicts graduates, it’s often wrong.\n",
    "\n",
    "The model now identifies 67% of actual graduates (recall_score of 0.67), which is a big improvement from 0% recall earlier. However, it now misses many non-graduates (recall dropped from 1.00 to 0.47).\n",
    "\n",
    "Graduates (class 1) have a usable but modest F1-score compared to before (previously 0.00).\n",
    "\n",
    "Accuracy dropped because the model now misclassifies more non-graduates in favor of catching graduates, this is normal when handling class imbalance.\n",
    "\n",
    "Macro and weighted averages are closer, suggesting less bias toward class 0.\n",
    "\n",
    "Our F1-scores are moderate, indicating features or model complexity could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7611708-b771-46a7-ac9c-4208bd24f372",
   "metadata": {},
   "source": [
    " ## f. Stratified k-fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e168a8-80aa-4af6-8d77-258d3e767c08",
   "metadata": {},
   "source": [
    "With only 115 rows, a single 80/20 split means your test set has ~23 rows. Too small to trust. \n",
    "\n",
    "We use StratifiedKFold to preserves class balance instead of one fixed split.\n",
    "\n",
    "    Stratified 5-Fold CV - every observation gets a chance to be in test set, while keeping class balance.\n",
    "    \n",
    "    Produces aggregate predictions across folds - more reliable classification reports and confusion matrices.\n",
    "    \n",
    "    Avoids the “tiny test set” problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6899c3ed-2ff8-43e4-a2c0-90c4d78973ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro scores for each fold: [0.41025641 0.3030303  0.425      0.45591398 0.43047619]\n",
      "Mean F1-macro score: 0.40493537645150546\n",
      "Std deviation: 0.05304092298440999\n",
      "Mean Accuracy: 0.47826086956521746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Use all your preprocessed features and labels\n",
    "X_all = preprocessor.transform(pd.concat([X_train, X_test], axis=0).reset_index(drop=True)) # Preprocessed features for the whole dataset\n",
    "y_all = pd.concat([y_train, y_test], axis=0).reset_index(drop=True) # Target labels for the whole dataset\n",
    "\n",
    "#Define Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#Define the model with class balancing and best hyperparameters if available\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=500,\n",
    "    solver='liblinear',\n",
    "    C=1.0,  #Best C\n",
    "    penalty=\"l1\" #Best penalty\n",
    ")\n",
    "\n",
    "#Evaluate with F1-macro (better for class imbalance)\n",
    "scores = cross_val_score(log_reg, X_all, y_all, cv=skf, scoring='f1_macro')\n",
    "\n",
    "#Summarize results\n",
    "print(\"F1-macro scores for each fold:\", scores)\n",
    "print(\"Mean F1-macro score:\", np.mean(scores))\n",
    "print(\"Std deviation:\", np.std(scores))\n",
    "\n",
    "# Optional: Check accuracy too\n",
    "acc_scores = cross_val_score(log_reg, X_all, y_all, cv=skf, scoring='accuracy')\n",
    "print(\"Mean Accuracy:\", np.mean(acc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905b0a6-b3c6-4565-b13c-9d22c731ce6e",
   "metadata": {},
   "source": [
    "We have moderate variability between folds – the standard deviation of ≈0.053 suggests performance is somewhat stable, but not highly reliable.\n",
    "\n",
    "Low absolute F1-macro and accuracy – the classifier is struggling to separate graduates (class 1) from non-graduates (class 0).\n",
    "\n",
    "Class imbalance likely affects performance – even with class_weight='balanced', the model is biased toward the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d208d71-bbd9-4ea2-a7fa-e3bf636d2903",
   "metadata": {},
   "source": [
    "## h. Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361a3de-dfd3-498c-8db1-786fd57e8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Random Forest ---\n",
    "rf = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "results.append(evaluate_model(rf, X, y, \"Random Forest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a974b-b8f3-4597-816e-05054c8b8633",
   "metadata": {},
   "source": [
    "## i. Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1193bbc-ee2a-4299-8bad-bc416c34d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Naïve Bayes ---\n",
    "X_nb = X.copy()\n",
    "for col in cat_cols:\n",
    "    X_nb[col] = LabelEncoder().fit_transform(X_nb[col])\n",
    "nb = CategoricalNB()\n",
    "results.append(evaluate_model(nb, X_nb, y, \"Naïve Bayes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f390956-ab10-4b19-af6e-ef231615cbc1",
   "metadata": {},
   "source": [
    "## j. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819e936-e1f2-47f3-ae6e-a3292aba9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. CatBoost \n",
    "try:\n",
    "    preds = []\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        model = cb.CatBoostClassifier(verbose=0, random_state=42)\n",
    "        model.fit(X_train, y_train, cat_features=[X.columns.get_loc(c) for c in cat_cols])\n",
    "        preds.extend(model.predict(X_test))\n",
    "    results.append({\n",
    "        \"Model\": \"CatBoost\",\n",
    "        \"Accuracy\": accuracy_score(y, preds),\n",
    "        \"Precision\": precision_score(y, preds, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y, preds, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y, preds, average=\"weighted\", zero_division=0)\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(\"CatBoost skipped:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3436dc-0ac2-46c7-ae86-95713b98e79e",
   "metadata": {},
   "source": [
    "## k. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8c0ed-be74-4f29-995d-b3a66c484733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Results table ---\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(df_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
